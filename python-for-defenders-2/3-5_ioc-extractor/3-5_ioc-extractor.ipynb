{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd73326-eb30-41c0-bc9c-624253328635",
   "metadata": {},
   "source": [
    "# 3-5: Lab - IoC Extractor\n",
    "\n",
    "It's time to build a real tool with all we've learned! We're going to solve a GIANT problem defenders face constantly: extracting indicators from garbage source files.\n",
    "\n",
    "Sometimes, indicators are received in mixed formats. MD5 hashes, SHA1s, SHA256s, IPs, domains, and URLs are all jumbled together.\n",
    "\n",
    "Sometimes, some sadistic monster decides to provide all of these in a PDF for no reason other than to make us suffer.\n",
    "\n",
    "But that ends now.\n",
    "\n",
    "Our IoC extractor will take any text file, find all the strings matching our indicator patterns, and produce either a CSV or JSON for easy ingestion into our defensive tools.\n",
    "\n",
    "We'll build it using widgets to make it easy to work with.\n",
    "\n",
    "Let's import what we'll need.\n",
    "\n",
    "**NOTE: We're gonna use a new library, `pdfplumber`, to handle PDFs. Don't worry; we'll cover it when it comes up.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0619fb-1136-4d88-9130-b8eba18d1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our gear\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "import csv\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5a212-2ac8-4fe2-a187-0f239c01d0f9",
   "metadata": {},
   "source": [
    "## Step 1: Acquire Files\n",
    "\n",
    "First we need the files. Let's get 'em, widget-style!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0114efe7-97b7-46d4-b71c-9cb434798a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fcee3de8fe40159370d146176a4e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Upload File(s)'), FileUpload(value={}, accept='.csv, .txt, .json, .pdf, .html', de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define and display widgets\n",
    "upload = widgets.FileUpload(multiple=True, accept=\".csv, .txt, .json, .pdf, .html\")\n",
    "label = widgets.Label(value=\"Upload File(s)\")\n",
    "box = widgets.HBox([label, upload])\n",
    "display(box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92e98e-a3ca-4341-81a2-6ba72798d09c",
   "metadata": {},
   "source": [
    "## Step 2: Extract Raw Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2dd72-2238-466f-a405-3aae63776d33",
   "metadata": {},
   "source": [
    "Something kind of counterintuitive about this process is that, with the exception of PDFs, we don't really care about what kind of file it us. We just want the raw text, because we'll be doing our own parsing of the content to look for our patterns. PDFs present a special challenge because they are not plain text; they are binary blobs. That's why we imported the `pdfplumber` module to help us out.\n",
    "\n",
    "Let's briefly discuss how to use `pdfplumber`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762088e-d118-41a3-be01-302e1d998e7d",
   "metadata": {},
   "source": [
    "### `pdfplumber`\n",
    "\n",
    "Since PDFs are binary blobs, we can't just do `with...open...readlines()`. But that's okay; the plumber has us covered. `pdfplumber.open()` takes a path and returns a `PDF` object. This object in turn contains a `pages` property that holds a bunch of `Page` objects. FINALLY, those `Page` objects have an `.extract_text()` method that will stringify the contents of the page! Check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038f4bb9-b916-4d45-be09-bc0e9b8faf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10/10/22, 7:08 PM Bad VIB(E)s Part One: Investigating Novel Malware Persistence Within ESXi Hypervisors | Mandiant\\nMandiant is now part of Google Cloud. Learn More.\\n\\ue5cf\\nEN\\nBLOG\\nBad VIB(E)s Part One:\\nInvestigating Novel Malware\\nPersistence Within ESXi\\nHypervisors\\nALEXANDER MARVI, JEREMY KOPPEN, TUFAIL AHMED, JONATHAN LEPORE\\nSEP 29, 2022 | 16 MINS\\xa0READ\\n#MALWARE  #BACKDOOR\\nAs endpoint detection and response (EDR) solutions improve malware detection e\\x00cacy on\\nWindows systems, certain state-sponsored threat actors have shifted to developing and\\ndeploying malware on systems that do not generally support EDR such as network appliances,\\nSAN arrays, and VMware ESXi servers.\\nEarlier this year, Mandiant identiﬁed a novel malware ecosystem impacting VMware ESXi, Linux\\nvCenter servers, and Windows virtual machines that enables a threat actor to take the following\\nactions:\\n\\x00. Maintain persistent administrative access to the hypervisor\\n\\x00. Send commands to the hypervisor that will be routed to the guest VM for execution\\n\\x00. Transfer ﬁles between the ESXi hypervisor and guest machines running beneath it\\nhttps://www.mandiant.com/resources/blog/esxi-hypervisors-malware-persistence 1/18'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text\n",
    "with pdfplumber.open(\"esxi_mandiant.pdf\") as pdf:\n",
    "    text_pages = [p.extract_text() for p in pdf.pages]\n",
    "    \n",
    "# Review page 1\n",
    "text_pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055c5ac-cf7c-4ba3-8868-e0b694224931",
   "metadata": {},
   "source": [
    "Okay, so we plainly have a way to handle PDFs. Now we need the entire procedure for handling all our files. If it's plaintext, we can just grab it from the widget. But if it's binary, we'd be better off using `pdfplumber`. My first move would be to define some functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0062dd8-0e7e-4c56-af71-b91d92b18ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First our PDF extractor\n",
    "def get_pdf_text(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from file at pdf_path and returns a big ol' string of the results\n",
    "    \"\"\"\n",
    "    with pdfplumber.open(\"esxi_mandiant.pdf\") as pdf:\n",
    "        return \"\".join([p.extract_text() for p in pdf.pages])\n",
    "    \n",
    "def get_file_contents(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Seeks the upload widget for a given filename.\n",
    "    \n",
    "    If it's there and it's not a PDF, grabs the content as a string.\n",
    "    \n",
    "    PDFs, it will use the filename with get_pdf_text\n",
    "    \"\"\"\n",
    "    # Check for a PDF\n",
    "    if upload.value[filename][\"metadata\"][\"type\"] == \"application/pdf\":\n",
    "        return get_pdf_text(filename)\n",
    "    \n",
    "    # Otherwise, get the contents\n",
    "    return upload.value[filename][\"content\"].decode()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53bcf12-dc48-4827-a226-5660dc110871",
   "metadata": {},
   "source": [
    "Okay! Functions in hand, we can go get our data. We'll keep everything in a `dict` so we'll once again use that `dict` comprehension trick we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae7a91aa-3b3e-488c-a81a-dfe948f3b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "data: dict = {f: get_file_contents(f) for f in upload.value}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325109d9-2f9e-4d21-b8db-d4ae52dd3719",
   "metadata": {},
   "source": [
    "You can look at `data` if you want, but it's gonna be a hot mess so I'm leaving it alone for right now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804548a-7035-461c-b973-095447de648c",
   "metadata": {},
   "source": [
    "## Step 3: Match Patterns\n",
    "\n",
    "Data in hand, we need some ✨regular expressions✨ to match our patterns. What do our indicators look like? Luckily, our hashes have known lengths and URLs/domains/IPs are fairly simple.\n",
    "\n",
    "* `MD5`: 32 characters of lower case 0-9,a-f\n",
    "* `SHA1`: 40 characters of the same\n",
    "* `SHA256`: 64 \"\"\n",
    "* `SHA512`: 128 \"\"\n",
    "* `IPv4`: 1-3 digits and a dot, repeated 3 times, followed by 1-3 more digits\n",
    "* `domain`: A-Z,a-z,0-9,- separated by dots, ending in 2-n a-z characters\n",
    "* `URL`: `http`, maybe `s` `://`, a domain pattern, and any number of `/` followed by the same characters allowed in domains,plus`%`,`?`,`=`,`&`, and `+`.\n",
    "\n",
    "Now, we do have an extra complication here: overlaps. A SHA512 will contain 4 MD5 pattern matches! How do we avoid this issue? Negative lookarounds. We will use the `(?<![0-9a-f])` and `(?![0-9a-f])` patterns to discard matches with hex characters immediately before or after the smaller matches. This is some advanced regexery, but it's what we need here.\n",
    "\n",
    "It's Regex time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0285377-ae31-410f-8a17-7d25a87e7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our regexes\n",
    "# Yes, I'm giving these to you. Feel free to improve on them!\n",
    "md5_pattern = re.compile(r\"(?<![0-9a-f])[0-9a-f]{32}(?![0-9a-f])\")\n",
    "sha1_pattern = re.compile(r\"(?<![0-9a-f])[0-9a-f]{40}(?![0-9a-f])\")\n",
    "sha256_pattern = re.compile(r\"(?<![0-9a-f])[0-9a-f]{64}(?![0-9a-f])\")\n",
    "sha512_pattern = re.compile(r\"[0-9a-f]{128}\")\n",
    "ipv4_pattern = re.compile(r\"(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\")\n",
    "domain_pattern = re.compile(r\"(?:[A-Za-z0-9\\-]+\\.)+[A-Za-z]{2,}\")\n",
    "url_pattern = re.compile(r\"https?://(?:[A-Za-z0-9\\-]+\\.)+[A-Za-z0-9]{2,}(?::\\d{1,5})?[/A-Za-z0-9\\-%?=\\+\\.]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ac0cc-7c71-4753-bb96-d7b55ff110aa",
   "metadata": {},
   "source": [
    "Yeesh. With those in hand, it's time to parse our data. Again, we're building a `dict` whose keys are our filenames. Inside each is a `dict` whose keys are our match types. Easiest way here is with a loop.\n",
    "\n",
    "You might notice an unfamiliar bit of syntax in those regexes: `(?:...)`. These are _non-capturing groups_ which are necessary to prevent `.findall()` from returning just that group.\n",
    "\n",
    "Oh, one other thing. It's likely that a given file will have repeated indicators. We need an easy way to deduplicate our findings. We could write an algorithm to check and remove duplicates, but there's an easier way.\n",
    "\n",
    "The [`set`](https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset) data type is a sequence that enforces uniqueness. Converting a list to a set automatically deduplicates the elements. Sets are immutable, so we lose some flexibility, but they're fantastic for this exact use case.\n",
    "\n",
    "But, because we can't save `set`s as JSON, we're going to immediately convert them back to `list`s. This is the kind of nonsense that you'll see often in my code, and it's a symptom of training as a functional programmer. There are a lot of parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b1b62a8-06f1-47cb-bc5a-5ef5f2dbfda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'esxi_mandiant.pdf': {'md5': ['bd6e38b6ff85ab02c1a4325e8af29ce4',\n",
       "   '2c28ec2d541f555b2838099ca849f965',\n",
       "   '9d5cc1ee99ccb1ec4d20be1cee10173e',\n",
       "   '744e2a4c1da48869776827d461c2b2ec',\n",
       "   '61ab3f6401d60ec36cd3ac980a8deb75',\n",
       "   '93d50025b81d3dbcb2e25d15cae03428',\n",
       "   '8e80b40b1298f022c7f3a96599806c43',\n",
       "   '2716c60c28cf7f7568f55ac33313468b',\n",
       "   'fe34b7c071d96dac498b72a4a07cb246',\n",
       "   '9ea86dccd5bbde47f8641b62a1eeff07',\n",
       "   '76df41ee75d5077f2c5bec70747b3c99'],\n",
       "  'sha1': ['93d5c4ebec2aa45dcbd6ddbaad5d80614af82f84',\n",
       "   '5ffa6d539a4d7bf5aacc4d32e198cc1607d4a522',\n",
       "   '9d191849d6c57bc8a052ec3dac2aa9f57c3fe0cd',\n",
       "   'abff003edf67e77667f56bbcfc391e2175cb0f8a',\n",
       "   'e9cbac1f64587ce1dc5b92cde9637affb3b58577',\n",
       "   'b90b19781fde2c35963eb3eac4ce2acc6f5019fb',\n",
       "   '0962e10dc34256c6b31509a5ced498f8f6a3d6b6',\n",
       "   'a3cc666e0764e856e65275bd4f32a56d76e51420',\n",
       "   'e35733db8061b57b8fcdb83ab51a90d0a8ba618c',\n",
       "   '17fb90d01403cb3d1566c91560f8f4b7dd139aa8'],\n",
       "  'sha256': ['13f11c81331bdce711139f985e6c525915a72dc5443fbbfe99c8ec1dd7ad2209',\n",
       "   '23eb8d056f18e7c69ec3568f2833c9d09e91df98d11b11de235331ef42756fe5',\n",
       "   '4cf3e0b60e880e6a6ba9f45187ac5454813ae8c2031966d8b264ae0d1e15e70d',\n",
       "   '4d995eb87b0685124b7f1640d1ab431f5a1ab991ade02750b876ed5c523234bb',\n",
       "   '2be5f4520846bf493b4694789841907d058fe08d59fff6bad7abe1db8ed96e7d',\n",
       "   '5731d988781c9a1d2941f7333615f6292fb359f6d48498f32c29878b5bedf00f',\n",
       "   '505eb3b90cd107cf7e2c20189889afdff813b2fbb98bbdeab65cde520893b168',\n",
       "   '4a6f559426493abc0d056665f23457e2779abd3482434623e1f61f4cd5b41843',\n",
       "   'e68872c49aaedeb3bde3ff5fd2ad6f70658687dc02d04f12ebc7cb28e821cc88',\n",
       "   'c2ef08af063f6d416233a4b2b2e991c177fc72d70a76c24bca9080521d41040f'],\n",
       "  'sha512': [],\n",
       "  'ipv4': ['127.0.0.1'],\n",
       "  'domain': ['rc.local',\n",
       "   'vmsyslog.py',\n",
       "   'local.sh',\n",
       "   'b.ReadLine',\n",
       "   'rundll32.exe',\n",
       "   'wmpd.exe',\n",
       "   'rhttpio.sh',\n",
       "   'e.py',\n",
       "   'Text.Encoding',\n",
       "   'powershell.exe',\n",
       "   'vmtoolsd.exe',\n",
       "   'www.mandiant.com',\n",
       "   'b.Dispose',\n",
       "   'comsvcs.dll',\n",
       "   'cmd.exe',\n",
       "   'avp.exe',\n",
       "   'System.IO.streamReader'],\n",
       "  'url': ['https://www.mandiant.com/resources/blog/esxi-hypervisors-malware-persistence']}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty dict\n",
    "results = {}\n",
    "\n",
    "# Loop through our strings\n",
    "# Convert our findings to sets to deduplicate\n",
    "for d in data:\n",
    "    content = data[d]\n",
    "    results[d] = {\n",
    "        \"md5\": list(set(md5_pattern.findall(content))),\n",
    "        \"sha1\": list(set(sha1_pattern.findall(content))),\n",
    "        \"sha256\": list(set(sha256_pattern.findall(content))),\n",
    "        \"sha512\": list(set(sha512_pattern.findall(content))),\n",
    "        \"ipv4\": list(set(ipv4_pattern.findall(content))),\n",
    "        \"domain\": list(set(domain_pattern.findall(content))),\n",
    "        \"url\": list(set(url_pattern.findall(content))),\n",
    "    }\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56825b-b2c3-43dc-aef0-136887c519a0",
   "metadata": {},
   "source": [
    "Okay, so is it perfect? No. It turns out files with extensions are basically indistinguishable from domains. But otherwise, pretty solid! Let's take this and deliver our results. To do so, we'll offer 2 buttons: a CSV export, and a JSON export.\n",
    "\n",
    "Buttons are event-driven, so we also need to first write the functions that will perform the export."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb14cd-01dd-4e7b-a14a-7b17eec95a1c",
   "metadata": {},
   "source": [
    "## Step 4: Deliver Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9745e-490c-42a9-867c-b3050c6d4fa2",
   "metadata": {},
   "source": [
    "Reshaping our data into JSON format is essentially done for us. But flattening it out into a CSV, well, that's gonna be a little trickier.\n",
    "\n",
    "If we imagine our CSV with 3 columns, like so:\n",
    "\n",
    "**Filename** | **IOC Type** | **Value**\n",
    "--|--|--\n",
    "Foo.txt | domain | evil.com\n",
    "\n",
    "We can see that a bit of destructuring is necessary.\n",
    "\n",
    "For now, rather than be super elegant with it, we'll be clear. Sadly, this means it'll involve 2 nested loops (gross) and a list comprehension. So really 3 nested loops, but one is prettier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1a3fe9e-eaae-415c-9dca-d3ebd57941dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cca666a937e4761ba6a4cf30f3c6341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='CSV Export', style=ButtonStyle()), Button(description='JSON Export', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Give an output\n",
    "output = widgets.Output()\n",
    "# Create the buttons.\n",
    "json_button = widgets.Button(description=\"JSON Export\")\n",
    "csv_button = widgets.Button(description=\"CSV Export\")\n",
    "\n",
    "# Provide an output display\n",
    "box = widgets.HBox([csv_button, json_button, output])\n",
    "display(box)\n",
    "\n",
    "# Define filenames\n",
    "CSV_RESULTS: str = \"results.csv\"\n",
    "JSON_RESULTS: str = \"results.json\"\n",
    "\n",
    "# Create the export handlers\n",
    "def csv_export(b):\n",
    "    \n",
    "    with output:\n",
    "        header = [\"filename\", \"type\",\"value\"]\n",
    "        with open(CSV_RESULTS, \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header)\n",
    "            for filename in results:\n",
    "                # Add filename to the the dict\n",
    "                result = results[filename]\n",
    "                for ioc_type in result:                    \n",
    "                    iocs = result[ioc_type]\n",
    "                    rows = [[filename, ioc_type, i] for i in iocs]\n",
    "                    writer.writerows(rows)\n",
    "                    \n",
    "        # Notify when done\n",
    "        print(f\"{CSV_RESULTS} written\")\n",
    "        \n",
    "def json_export(b):\n",
    "    \n",
    "    with output:\n",
    "        with open(JSON_RESULTS, \"w\") as f:\n",
    "            json.dump(results, f)\n",
    "            print(f\"{JSON_RESULTS} written\")\n",
    "\n",
    "\n",
    "csv_button.on_click(csv_export)\n",
    "json_button.on_click(json_export)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa433c-e5d3-4299-a06a-e3f11b45fa4a",
   "metadata": {},
   "source": [
    "## Step 5: Celebrate!\n",
    "\n",
    "That's it! We now have a take-all-files IoC extractor. Remember that this file is meant to explain the lab, but that you should try to reproduce it in your own Notebook to understand in depth how each piece works.\n",
    "\n",
    "At long last, we're finished with our unit on Parsing. Up next, we move off our one computer and use Jupyter to connect to resources on the internet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287abef-48e6-471f-a490-1f03ed1c2e9b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Mandiant, 29 September 2022. [\"Bad VIB(E)s Part One: Investigating Novel Malware Persistence Within ESXi Hypervisors\"](https://www.mandiant.com/resources/blog/esxi-hypervisors-malware-persistence)\n",
    "2. AlienVault, 12 September 2022. [\"HEINEKEN Malaysia 'Free Beer' phishing scam circulating through social networks which has been detected by NetAssist Threat Intelligence team\"](https://otx.alienvault.com/pulse/632025d828a36b7ea31c11fa)\n",
    "3. CISA, 30 June 2022. [\"#StopRansomware: MedusaLocker\"](https://www.cisa.gov/uscert/ncas/alerts/aa22-181a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
