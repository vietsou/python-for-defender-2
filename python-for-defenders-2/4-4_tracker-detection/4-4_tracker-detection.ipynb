{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4d557f-9aab-446b-9c17-6ee144f628e6",
   "metadata": {},
   "source": [
    "# 4-4: Tracker Detection\n",
    "\n",
    "It isn't all about malware, you know.\n",
    "\n",
    "Being able to safely determine what a website does without using a browser is a common function of a defense team. Of particular interest is any tracking technologies in use by a site. You may have seen some recent news regarding one of the most insidious: the [Meta Pixel](https://developers.facebook.com/docs/meta-pixel/)\n",
    "\n",
    "Another common tracker is, of course, [Google Analytics](https://analytics.google.com/). \n",
    "\n",
    "If we want to identify whether a site is using these, we can use our parsing powers to do just that.\n",
    "\n",
    "We'll start by importing the stuff we know we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4b5fb-7a7c-4d86-96a7-6620e27b8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the basics\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd190b-90e2-479f-ae12-a383c3d5be9e",
   "metadata": {},
   "source": [
    "## Recon\n",
    "\n",
    "First, we need to know a little about what we're trying to identify. These trackers will have identifiable code snippets in page we analyze. For flexibility, we'll store these patterns in a `dict`. You can learn about the code that makes these trackers up in their documentation. For both Meta and Google, we're talking about JavaScript.\n",
    "\n",
    "Meta uses a script with the obvious pattern of a URL: `https://connect.facebook.net/en_US/fbevents.js`. Google uses a URL as well, but as a `src` attribute for its script. Another pattern we can use in the text of a script node is `gtag('config'`.\n",
    "\n",
    "So let's store those for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae26a4e-83de-47d7-bf9f-e944b98ccd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up patterns\n",
    "script_patterns = {\n",
    "    \"meta\": \"https://connect.facebook.net/en_US/fbevents.js\",\n",
    "    \"google\": \"gtag\\('config'\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c1fba-6df3-4687-9295-385555b7902f",
   "metadata": {},
   "source": [
    "Now we need a list of pages to search. You can add whatever pages you like to this list, but I'll kick it off with a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe202c-c93d-4d3e-aa11-74becf9b641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the list of sites\n",
    "sites = [\n",
    "    \"taggart-tech.com\",\n",
    "    \"shop.bbc.com\",\n",
    "    \"huffpost.com\",\n",
    "    \"discord.com\",\n",
    "    \"soundcloud.com\",\n",
    "    \"canva.com\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5fe01-3ce3-4d07-a236-d568ab57a4fa",
   "metadata": {},
   "source": [
    "Our results will be stored in a `dict` as well. For each site, we need to:\n",
    "\n",
    "1. Pull the web content\n",
    "2. Find all `script` tags\n",
    "3. Check if any of them match our patterns \n",
    "4. Report results\n",
    "\n",
    "A few key words in these steps give us hints about how to proceed. `any()` is a built-in. Python function that take 2 arguments: a function, and a sequence over which to iterate the function. The function must return a `bool`. If any of the elements return `True` when passed to the function, `any()` returns `True`. There's also an `all()` that works similarly, but `any()` will work for our purposes. So let's write the `pattern_match()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfae81-f68e-4854-989b-6e9cdee2b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_match(pattern: str, sample: str) -> bool:\n",
    "    \"\"\"\n",
    "    Checks whether a pattern is found in a sample\n",
    "    \"\"\"\n",
    "    return re.search(pattern, sample) != None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e3c31-7416-4ebc-882a-59813e669084",
   "metadata": {},
   "source": [
    "It isn't much, but it will provide what we need to pass to `any()`...sorta.\n",
    "\n",
    "But first, let's initialize our results `dict`. The shape will be `{site: [tracker names]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337188b1-4876-4138-8b60-8d2c221d49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463e89a-7392-4bc7-b198-210b2a9e9485",
   "metadata": {},
   "source": [
    "So now we need to loop through our sites, grab the `script` elements, and check for patterns with `any()`. The idea here is that if any of the `script` elements match our pattern, we know we have the given tracker.\n",
    "\n",
    "This is one of those instances where a `for` loop is absolutely more appropriate than a list comprehension for readability and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a55498-a6ab-4e10-9644-838cb7e9cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through sites\n",
    "for s in sites:\n",
    "    # Initialize site list\n",
    "    results[s] = []\n",
    "    # Get content\n",
    "    content: str = requests.get(f\"https://{s}\").text\n",
    "    soup = BeautifulSoup(content)\n",
    "    # Find script tags\n",
    "    # Extract just the text to get the raw str\n",
    "    script_tags = [ t.text for t in soup.find_all(\"script\") ]\n",
    "    # Loop through patterns to check\n",
    "    for p in script_patterns:\n",
    "        pattern: str = script_patterns[p]\n",
    "        # Check if any of the scripts have the pattern\n",
    "        if any([pattern_match(pattern, t) for t in script_tags]):\n",
    "            results[s].append(p)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee041dd1-4bf6-463f-bdc2-9da811be84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6006f-718f-4002-b7c8-6c02a43c5c9f",
   "metadata": {},
   "source": [
    "Change the sites up for different results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01944f3b-b6a6-42af-88ae-2009dd8a5560",
   "metadata": {},
   "source": [
    "## Going Further\n",
    "\n",
    "One of my favorite tools for web app testing is [Wappalyzer](https://www.wappalyzer.com/), which will detect technologies in use on a page via server headers and source analysis. We're going a simplistic version of this here, but wouldn't you know it: Wappalyzer has a [Python module](https://pypi.org/project/python-Wappalyzer/)!\n",
    "\n",
    "Because I'm cool like that, I've already added it as a dependency in this environment. See if you can rework this lab using Wappalyzer to detect WordPress sites or other technology!\n",
    "\n",
    "And that closes out section 4! Up next, we begin to analyze our data with scientific tools!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
